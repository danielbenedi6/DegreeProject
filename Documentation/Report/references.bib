@article{MARKRAM201139,
title = {Introducing the Human Brain Project},
journal = {Procedia Computer Science},
volume = {7},
pages = {39-42},
year = {2011},
note = {Proceedings of the 2nd European Future Technologies Conference and Exhibition 2011 (FET 11)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911006806},
author = {Henry Markram and Karlheinz Meier and Thomas Lippert and Sten Grillner and Richard Frackowiak and Stanislas Dehaene and Alois Knoll and Haim Sompolinsky and Kris Verstreken and Javier DeFelipe and Seth Grant and Jean-Pierre Changeux and Alois Saria},
keywords = {Human brain, neuroscience, neuroinformatics, modeling, simulation, supercomputing, HPC, medicine, neuromorphics, neuroprosthetics, neurorobotics},
abstract = {The Human Brain Project (HBP) is a candidate project in the European Union's FET Flagship Program, funded by the ICT Program in the Seventh Framework Program. The project will develop a new integrated strategy for understanding the human brain and a novel research platform that will integrate all the data and knowledge we can acquire about the structure and function of the brain and use it to build unifying models that can be validated by simulations running on supercomputers. The project will drive the development of supercomputing for the life sciences, generate new neuroscientific data as a benchmark for modeling, develop radically new tools for informatics, modeling and simulation, and build virtual laboratories for collaborative basic and clinical studies, drug simulation and virtual prototyping of neuroprosthetic, neuromorphic, and robotic devices.}
}
@article{HERCULANO2012,
author = {Suzana Herculano-Houzel },
title = {The remarkable, yet not extraordinary, human brain as a scaled-up primate brain and its associated cost},
journal = {Proceedings of the National Academy of Sciences},
volume = {109},
number = {supplement\_1},
pages = {10661-10668},
year = {2012},
doi = {10.1073/pnas.1201895109},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1201895109},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1201895109},
abstract = {Neuroscientists have become used to a number of “facts” about the human brain: It has 100 billion neurons and 10- to 50-fold more glial cells; it is the largest-than-expected for its body among primates and mammals in general, and therefore the most cognitively able; it consumes an outstanding 20\% of the total body energy budget despite representing only 2\% of body mass because of an increased metabolic need of its neurons; and it is endowed with an overdeveloped cerebral cortex, the largest compared with brain size. These facts led to the widespread notion that the human brain is literally extraordinary: an outlier among mammalian brains, defying evolutionary rules that apply to other species, with a uniqueness seemingly necessary to justify the superior cognitive abilities of humans over mammals with even larger brains. These facts, with deep implications for neurophysiology and evolutionary biology, are not grounded on solid evidence or sound assumptions, however. Our recent development of a method that allows rapid and reliable quantification of the numbers of cells that compose the whole brain has provided a means to verify these facts. Here, I review this recent evidence and argue that, with 86 billion neurons and just as many nonneuronal cells, the human brain is a scaled-up primate brain in its cellular composition and metabolic cost, with a relatively enlarged cerebral cortex that does not have a relatively larger number of brain neurons yet is remarkable in its cognitive abilities and metabolism simply because of its extremely large number of neurons.}}
 @misc{ wiki:interneurons,
   author = "Physiopedia",
   title = "Interneurons --- Physiopedia{,} ",
   year = "2022",
   url = "https://www.physio-pedia.com/index.php?title=Interneurons&oldid=304286",
   note = "[Online; accessed 10-May-2022]"
 }
 @ARTICLE{Reimann2015-ys,
  title     = "An algorithm to predict the connectome of neural microcircuits",
  author    = "Reimann, Michael W and King, James G and Muller, Eilif B and
               Ramaswamy, Srikanth and Markram, Henry",
  abstract  = "Experimentally mapping synaptic connections, in terms of the
               numbers and locations of their synapses and estimating
               connection probabilities, is still not a tractable task, even
               for small volumes of tissue. In fact, the six layers of the
               neocortex contain thousands of unique types of synaptic
               connections between the many different types of neurons, of
               which only a handful have been characterized experimentally.
               Here we present a theoretical framework and a data-driven
               algorithmic strategy to digitally reconstruct the complete
               synaptic connectivity between the different types of neurons in
               a small well-defined volume of tissue-the micro-scale connectome
               of a neural microcircuit. By enforcing a set of established
               principles of synaptic connectivity, and leveraging
               interdependencies between fundamental properties of neural
               microcircuits to constrain the reconstructed connectivity, the
               algorithm yields three parameters per connection type that
               predict the anatomy of all types of biologically viable synaptic
               connections. The predictions reproduce a spectrum of
               experimental data on synaptic connectivity not used by the
               algorithm. We conclude that an algorithmic approach to the
               connectome can serve as a tool to accelerate experimental
               mapping, indicating the minimal dataset required to make useful
               predictions, identifying the datasets required to improve their
               accuracy, testing the feasibility of experimental measurements,
               and making it possible to test hypotheses of synaptic
               connectivity.",
  journal   = "Front. Comput. Neurosci.",
  publisher = "Frontiers Media SA",
  volume    =  9,
  pages     = "120",
  month     =  oct,
  year      =  2015,
  keywords  = "algorithm development; connectome mapping; cortical circuits; in
               silico; neocortex; somatosensory cortex; synaptic transmission",
  language  = "en"
}
@inproceedings{Furber2006,
title = "High-performance computing for systems of spiking neurons",
abstract = "We propose a bottom-up computer engineering approach to the Grand Challenge of understanding the Architecture of Brain and Mind as a viable complement to top-down modelling and alternative approaches informed by the skills and philosophies of other disciplines. Our approach starts from the observation that brains are built from spiking neurons and then progresses by looking for a systematic way to deploy spiking neurons as components from which useful information processing functions can be constructed, at all stages being informed (but not constrained) by the neural structures and microarchitectures observed by neuroscientists as playing a role in biological systems. In order to explore the behaviours of large-scale complex systems of spiking neuron components we require high-performance computing equipment, and we propose the construction of a machine specifically for this task - a massively parallel computer designed to be a universal spiking neural network simulation engine.",
author = "S.B Furber and Steve Temple and Andrew Brown",
year = "2006",
language = "English",
volume = "2",
pages = "29--36",
booktitle = "Proceedings of AISB'06: Adaptation in Artificial and Biological Systems",
note = "AISB'06: Adaptation in Artificial and Biological Systems ; Conference date: 03-04-2006 Through 06-04-2006",

}
@phdthesis{Adamsson_Vorkapic_2016,
title={A comparison study of Kd-tree, Vp-tree and Octree for storing neuronal morphology data with respect to performance},
url={http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-187026},
abstractNote={In this thesis we investigated performance of Kdtree, Vptree and Octree for storing neuronal morphology data. Two naive list structures were implemented to compare with the space partition data structures. The performance was measured with different sizes of neuronal networks and different types of test cases. A comparison with focus on cache misses, average search time and memory usage was made. Furthermore, measurements gathered quantitative data about each data structure. The results showed significant difference in performance of each data structure. It was concluded that Vptree is more suitable for searches in smaller populations of neurons and for specific nodes in larger populations, while Kdtree is better for volume searches in larger populations. Octree had highest average search time and memory requirement.},
author={Adamsson, Marcus and Vorkapic, Aleksandar}, 
year={2016}
}
@article{10.1145/965105.807481,
author = {Fuchs, Henry and Kedem, Zvi M. and Naylor, Bruce F.},
title = {On Visible Surface Generation by a Priori Tree Structures},
year = {1980},
issue_date = {July 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {0097-8930},
url = {https://doi.org/10.1145/965105.807481},
doi = {10.1145/965105.807481},
abstract = {This paper describes a new algorithm for solving the hidden surface (or line) problem, to more rapidly generate realistic images of 3-D scenes composed of polygons, and presents the development of theoretical foundations in the area as well as additional related algorithms. As in many applications the environment to be displayed consists of polygons many of whose relative geometric relations are static, we attempt to capitalize on this by preprocessing the environment's database so as to decrease the run-time computations required to generate a scene. This preprocessing is based on generating a “binary space partitioning” tree whose in order traversal of visibility priority at run-time will produce a linear order, dependent upon the viewing position, on (parts of) the polygons, which can then be used to easily solve the hidden surface problem. In the application where the entire environment is static with only the viewing-position changing, as is common in simulation, the results presented will be sufficient to solve completely the hidden surface problem.},
journal = {SIGGRAPH Comput. Graph.},
month = {jul},
pages = {124–133},
numpages = {10}
}
@article{Fuchs1980,
author = {Fuchs, Henry and Kedem, Zvi M. and Naylor, Bruce F.},
title = {On Visible Surface Generation by a Priori Tree Structures},
year = {1980},
isbn = {0897910214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800250.807481},
doi = {10.1145/800250.807481},
abstract = {This paper describes a new algorithm for solving the hidden surface (or line) problem, to more rapidly generate realistic images of 3-D scenes composed of polygons, and presents the development of theoretical foundations in the area as well as additional related algorithms. As in many applications the environment to be displayed consists of polygons many of whose relative geometric relations are static, we attempt to capitalize on this by preprocessing the environment's database so as to decrease the run-time computations required to generate a scene. This preprocessing is based on generating a “binary space partitioning” tree whose in order traversal of visibility priority at run-time will produce a linear order, dependent upon the viewing position, on (parts of) the polygons, which can then be used to easily solve the hidden surface problem. In the application where the entire environment is static with only the viewing-position changing, as is common in simulation, the results presented will be sufficient to solve completely the hidden surface problem.},
booktitle = {Proceedings of the 7th Annual Conference on Computer Graphics and Interactive Techniques},
pages = {124–133},
numpages = {10},
location = {Seattle, Washington, USA},
series = {SIGGRAPH '80}
}
@article{Bentley,
author = {Bentley, Jon Louis},
title = {Multidimensional Binary Search Trees Used for Associative Searching},
year = {1975},
issue_date = {Sept. 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/361002.361007},
doi = {10.1145/361002.361007},
abstract = {This paper develops the multidimensional binary search tree (or k-d tree, where k is the dimensionality of the search space) as a data structure for storage of information to be retrieved by associative searches. The k-d tree is defined and examples are given. It is shown to be quite efficient in its storage requirements. A significant advantage of this structure is that a single data structure can handle many types of queries very efficiently. Various utility algorithms are developed; their proven average running times in an n record file are: insertion, O(log n); deletion of the root, O(n(k-1)/k); deletion of a random node, O(log n); and optimization (guarantees logarithmic performance of searches), O(n log n). Search algorithms are given for partial match queries with t keys specified [proven maximum running time of O(n(k-t)/k)] and for nearest neighbor queries [empirically observed average running time of O(log n).] These performances far surpass the best currently known algorithms for these tasks. An algorithm is presented to handle any general intersection query. The main focus of this paper is theoretical. It is felt, however, that k-d trees could be quite useful in many applications, and examples of potential uses are given.},
journal = {Commun. ACM},
month = {sep},
pages = {509–517},
numpages = {9},
keywords = {intersection queries, information retrieval system, attribute, binary search trees, partial match queries, key, nearest neighbor queries, associative retrieval, binary tree insertion}
}

@article{LinjiaSaeidMajid,

  author={Hu, Linjia and Nooshabadi, Saeid and Ahmadi, Majid},

  booktitle={2015 IEEE International Symposium on Circuits and Systems (ISCAS)}, 

  title={Massively parallel KD-tree construction and nearest neighbor search algorithms}, 

  year={2015},

  volume={},

  number={},

  pages={2752-2755},

  abstract={This paper presents parallel algorithms for the construction of k dimensional tree (KD-tree) and nearest neighbor search (NNS) on massively parallel architecture (MPA) of graphics processing unit (GPU). Unlike previous parallel algorithms for KD-tree, for the first time, our parallel algorithms integrate high dimensional KD-tree construction and NNS on an MPA platform. The proposed massively parallel algorithms are of comparable quality as traditional sequential counterparts on CPU, while achieve high speedup performance on both low and high dimensional KD-tree. Low dimensional KD-tree construction and NNS algorithms, presented in this paper, outperform their serial CPU counterparts by a factor of up to 24 and 218, respectively. For high dimensional KD-tree, the speedup factors are even higher, raising to 30 and 242, respectively. Our implementations will potentially benefit real time three-dimensional (3D) image registration and high dimensional descriptor matching.},

  keywords={},

  doi={10.1109/ISCAS.2015.7169256},

  ISSN={2158-1525},

  month={May},
}



@article{WaldHavran06,

  author={Wald, Ingo and Havran, Vlastimil},

  booktitle={2006 IEEE Symposium on Interactive Ray Tracing}, 

  title={On building fast kd-Trees for Ray Tracing, and on doing that in O(N log N)}, 

  year={2006},

  volume={},

  number={},

  pages={61-69},

  abstract={Though a large variety of efficiency structures for ray tracing exist, kd-trees today seem to slowly become the method of choice. In particular, kd-trees built with cost estimation functions such as a surface area heuristic (SAH) seem to be important for reaching high performance. Unfortunately, most algorithms for building such trees have a time complexity of O(N log<sup>2</sup> N), or even O(N<sup>2</sup>). In this paper, we analyze the state of the art in building good kd-trees for ray tracing, and eventually propose an algorithm that builds SAH kd-trees in O(N log N), the theoretical lower bound},

  keywords={},

  doi={10.1109/RT.2006.280216},

  ISSN={},

  month={Sep.},
}

@article{Yucheng,
author = {Lu, Yucheng and Cheng, Luyu and Isenberg, Tobias and Fu, Chi-Wing and Chen, Guoning and Liu, Hui and Deussen, Oliver and Wang, Yunhai},
title = {Curve Complexity Heuristic KD-trees for Neighborhood-based Exploration of 3D Curves},
journal = {Computer Graphics Forum},
volume = {40},
number = {2},
pages = {461-474},
keywords = {CCS Concepts, Human-centered computing → Scientific visualization, Theory of computation → Nearest neighbor algorithms},
doi = {https://doi.org/10.1111/cgf.142647},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.142647},
abstract = {Abstract We introduce the curve complexity heuristic (CCH), a KD-tree construction strategy for 3D curves, which enables interactive exploration of neighborhoods in dense and large line datasets. It can be applied to searches of k-nearest curves (KNC) as well as radius-nearest curves (RNC). The CCH KD-tree construction consists of two steps: (i) 3D curve decomposition that takes into account curve complexity and (ii) KD-tree construction, which involves a novel splitting and early termination strategy. The obtained KD-tree allows us to improve the speed of existing neighborhood search approaches by at least an order of magnitude (i. e., 28×for KNC and 12×for RNC with 98\% accuracy) by considering local curve complexity. We validate this performance with a quantitative evaluation of the quality of search results and computation time. Also, we demonstrate the usefulness of our approach for supporting various applications such as interactive line queries, line opacity optimization, and line abstraction.},
year = {2021}
}

@INPROCEEDINGS{7169256,
  author={Hu, Linjia and Nooshabadi, Saeid and Ahmadi, Majid},
  booktitle={2015 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Massively parallel KD-tree construction and nearest neighbor search algorithms}, 
  year={2015},
  volume={},
  number={},
  pages={2752-2755},
  doi={10.1109/ISCAS.2015.7169256}
}
@article{Sherwood2020,
    author = {Sherwood, Chet C and Miller, Sarah B and Karl, Molly and Stimpson, Cheryl D and Phillips, Kimberley A and Jacobs, Bob and Hof, Patrick R and Raghanti, Mary Ann and Smaers, Jeroen B},
    title = "{Invariant Synapse Density and Neuronal Connectivity Scaling in Primate Neocortical Evolution}",
    journal = {Cerebral Cortex},
    volume = {30},
    number = {10},
    pages = {5604-5615},
    year = {2020},
    month = {06},
    abstract = "{Synapses are involved in the communication of information from one neuron to another. However, a systematic analysis of synapse density in the neocortex from a diversity of species is lacking, limiting what can be understood about the evolution of this fundamental aspect of brain structure. To address this, we quantified synapse density in supragranular layers II–III and infragranular layers V–VI from primary visual cortex and inferior temporal cortex in a sample of 25 species of primates, including humans. We found that synapse densities were relatively constant across these levels of the cortical visual processing hierarchy and did not significantly differ with brain mass, varying by only 1.9-fold across species. We also found that neuron densities decreased in relation to brain enlargement. Consequently, these data show that the number of synapses per neuron significantly rises as a function of brain expansion in these neocortical areas of primates. Humans displayed the highest number of synapses per neuron, but these values were generally within expectations based on brain size. The metabolic and biophysical constraints that regulate uniformity of synapse density, therefore, likely underlie a key principle of neuronal connectivity scaling in primate neocortical evolution.}",
    issn = {1047-3211},
    doi = {10.1093/cercor/bhaa149},
    url = {https://doi.org/10.1093/cercor/bhaa149},
    eprint = {https://academic.oup.com/cercor/article-pdf/30/10/5604/38848884/bhaa149.pdf},
}
@ARTICLE{Neuromorpho1,
  title     = "Mobilizing the base of neuroscience data: the case of neuronal
               morphologies",
  author    = "Ascoli, Giorgio A",
  abstract  = "Despite the explosive growth of bioinformatics, data sharing has
               not yet become routine in neuroscience, possibly because of
               several broad-spanning issues, from data heterogeneity to
               privacy regulations. We present the case of neuronal morphology
               as an ideal example of shareable data. Drawing from recent
               experience, we argue that the tremendous research potential of
               existing (and largely unused) digital reconstructions should
               diffuse any reticence to sharing this type of data.",
  journal   = "Nat. Rev. Neurosci.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  7,
  number    =  4,
  pages     = "318--324",
  month     =  apr,
  year      =  2006,
  language  = "en"
}

@ARTICLE{Neuromorpho2,
  title     = "{NeuroMorpho.Org}: a central resource for neuronal morphologies",
  author    = "Ascoli, Giorgio A and Donohue, Duncan E and Halavi, Maryam",
  journal   = "J. Neurosci.",
  publisher = "Society for Neuroscience",
  volume    =  27,
  number    =  35,
  pages     = "9247--9251",
  month     =  aug,
  year      =  2007,
  language  = "en"
}

@book{carnevale2006neuron,
  title={The NEURON book},
  author={Carnevale, Nicholas T and Hines, Michael L},
  year={2006},
  publisher={Cambridge University Press}
}
@article{8671560,

  author={Akar, Nora Abi and Cumming, Ben and Karakasis, Vasileios and Küsters, Anne and Klijn, Wouter and Peyser, Alexander and Yates, Stuart},

  booktitle={2019 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)}, 

  title={Arbor — A Morphologically-Detailed Neural Network Simulation Library for Contemporary High-Performance Computing Architectures}, 

  year={2019},

  volume={},

  number={},

  pages={274-282},

  abstract={We introduce Arbor, a performance portable library for simulation of large networks of multi-compartment neurons on HPC systems. Arbor is open source software, developed under the auspices of the HBP. The performance portability is by virtue of back-end specific optimizations for x86 multicore, Intel KNL, and NVIDIA GPUs. When coupled with low memory overheads, these optimizations make Arbor an order of magnitude faster than the most widely-used comparable simulation software. The single-node performance can be scaled out to run very large models at extreme scale with efficient weak scaling.},

  keywords={},

  doi={10.1109/EMPDP.2019.8671560},

  ISSN={2377-5750},

  month={Feb},}
@article{Stimberg2019,
    title = {Brian 2, an intuitive and efficient neural simulator},
    volume = {8},
    issn = {2050-084X},
    doi = {10.7554/eLife.47314},
    journal = {eLife},
    author = {Stimberg, Marcel and Brette, Romain and Goodman, Dan FM},
    editor = {Skinner, Frances K},
    month = aug,
    year = {2019},
    pages = {e47314}
}
@ARTICLE{10.3389/fninf.2011.00015,
  
AUTHOR={Kozloski, James and Wagner, John},   
	 
TITLE={An Ultrascalable Solution to Large-scale Neural Tissue Simulation},      
	
JOURNAL={Frontiers in Neuroinformatics},      
	
VOLUME={5},      
	
YEAR={2011},      
	  
URL={https://www.frontiersin.org/article/10.3389/fninf.2011.00015},       
	
DOI={10.3389/fninf.2011.00015},      
	
ISSN={1662-5196},   
   
ABSTRACT={Neural tissue simulation extends requirements and constraints of previous neuronal and neural circuit simulation methods, creating a tissue coordinate system. We have developed a novel tissue volume decomposition, and a hybrid branched cable equation solver. The decomposition divides the simulation into regular tissue blocks and distributes them on a parallel multithreaded machine. The solver computes neurons that have been divided arbitrarily across blocks. We demonstrate thread, strong, and weak scaling of our approach on a machine with more than 4000 nodes and up to four threads per node. Scaling synapses to physiological numbers had little effect on performance, since our decomposition approach generates synapses that are almost always computed locally. The largest simulation included in our scaling results comprised 1 million neurons, 1 billion compartments, and 10 billion conductance-based synapses and gap junctions. We discuss the implications of our ultrascalable Neural Tissue Simulator, and with our results estimate requirements for a simulation at the scale of a human brain.}
}

@article{TPRtree,
author = {Tao, Yufei and Papadias, Dimitris and Sun, Jimeng},
title = {The TPR*-Tree: An Optimized Spatio-Temporal Access Method for Predictive Queries},
year = {2003},
isbn = {0127224424},
publisher = {VLDB Endowment},
abstract = {A predictive spatio-temporal query retrieves the set of moving objects that will intersect a query window during a future time interval. Currently, the only access method for processing such queries in practice is the TPR-tree. In this paper we first perform an analysis to determine the factors that affect the performance of predictive queries and show that several of these factors are not considered by the TPR-tree, which uses the insertion/deletion algorithms of the R*-tree designed for static data. Motivated by this, we propose a new index structure called the TPR*- tree, which takes into account the unique features of dynamic objects through a set of improved construction algorithms. In addition, we provide cost models that determine the optimal performance achievable by any data-partition spatio-temporal access method. Using experimental comparison, we illustrate that the TPR*-tree is nearly-optimal and significantly outperforms the TPR-tree under all conditions.},
booktitle = {Proceedings of the 29th International Conference on Very Large Data Bases - Volume 29},
pages = {790–801},
numpages = {12},
location = {Berlin, Germany},
series = {VLDB '03}
}

@online{wiki:octree,
 author  = "Nü",
 title   = "Schematic drawing of an octree, a data structure of computer science.",
 year    = "2006",
 urlseen = "2022/05/12",
 url     = "https://commons.wikimedia.org/wiki/File:Octree2.png",
 note    = "File: \ttfamily{Octree2.png}",
}

@book{Octree,
author = {Meagher, Donald},
year = {1980},
month = {10},
pages = {},
title = {Octree Encoding: A New Technique for the Representation, Manipulation and Display of Arbitrary 3-D Objects by Computer}
}

@ARTICLE{Quadtree,
  title     = "Quad trees a data structure for retrieval on composite keys",
  author    = "Finkel, R A and Bentley, J L",
  abstract  = "The quad tree is a data structure appropriate for storing information to be retrieved on composite keys. We discuss the specific case of two-dimensional retrieval, although the structure is easily generalised to arbitrary dimensions. Algorithms are given both for staightforward insertion and for a type of balanced insertion into quad trees. Empirical analyses show that the average time for insertion is logarithmic with the tree size. An algorithm for retrieval within regions is presented along with data from empirical studies which imply that searching is reasonably efficient. We define an optimized tree and present an algorithm to accomplish optimization in n log n time. Searching is guaranteed to be fast in optimized trees. Remaining problems include those of deletion from quad trees and merging of quad trees, which seem to be inherently difficult operations.",
  journal   = "Acta Inform.",
  publisher = "Springer Nature",
  volume    =  4,
  number    =  1,
  pages     = "1--9",
  year      =  1974,
  language  = "en"
}

@online{wiki:rtree,
 author  = "Chire",
 title   = "Visulization of a 3D R-tree using ELKI.",
 year    = "2010",
 urlseen = "2022/05/12",
 url     = "https://commons.wikimedia.org/wiki/File:RTree-Visualization-3D.svg",
 note    = "File: \ttfamily{RTree-Visualization-3d.svg}",
}

@article{10.1145/971697.602266,
author = {Guttman, Antonin},
title = {R-Trees: A Dynamic Index Structure for Spatial Searching},
year = {1984},
issue_date = {June 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/971697.602266},
doi = {10.1145/971697.602266},
abstract = {In order to handle spatial data efficiently, as required in computer aided design and geo-data applications, a database system needs an index mechanism that will help it retrieve data items quickly according to their spatial locations However, traditional indexing methods are not well suited to data objects of non-zero size located m multi-dimensional spaces In this paper we describe a dynamic index structure called an R-tree which meets this need, and give algorithms for searching and updating it. We present the results of a series of tests which indicate that the structure performs well, and conclude that it is useful for current database systems in spatial applications},
journal = {SIGMOD Rec.},
month = {jun},
pages = {47–57},
numpages = {11}
}

  
@online{wiki:kdtree,
 author  = "KiwiSunset",
 title   = " A visualization of results obtained by running the Python kd-tree-construction program on [(2,3), (5,4), (9,6), (4,7), (8,1), (7,2)]. ",
 year    = "2006",
 urlseen = "2022/05/12",
 url     = "https://commons.wikimedia.org/wiki/File:Kdtree_2d.svg",
 note    = "File: \ttfamily{Kdtree_2d.svg}",
}

 @phdthesis{Adamsson_Vorkapic_2016, 
    title={A comparison study of Kd-tree, Vp-tree and Octree for storing neuronal morphology data with respect to performance}, 
    url={http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-187026}, 
    abstractNote={In this thesis we investigated performance of Kdtree, Vptree and Octree for storing neuronal morphology data. Two naive list structures were implemented to compare with the space partition data structures. The performance was measured with different sizes of neuronal networks and different types of test cases. A comparison with focus on cache misses, average search time and memory usage was made. Furthermore, measurements gathered quantitative data about each data structure. The results showed significant difference in performance of each data structure. It was concluded that Vptree is more suitable for searches in smaller populations of neurons and for specific nodes in larger populations, while Kdtree is better for volume searches in larger populations. Octree had highest average search time and memory requirement.}, 
    author={Adamsson, Marcus and Vorkapic, Aleksandar}, 
    year={2016}
}

 @phdthesis{Brask_Berendt_2020, 
    series={TRITA-EECS-EX}, 
    title={Analyzing the scalability of R*-tree regarding the neuron touch detection task},
    url={http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-279973},
    abstractNote={A common task within research of neuronal morphology is neuron touch detection, that is finding the points in space where two neurites approach each other to form a synapse. In order to make efficient use of cache memory, it is important to store points that are close in space close in memory. One data structure that aims to tackle this complication is the R*-tree. In this thesis, a spatial query for touch detection was implemented and the scalability of the R*-tree was estimated on realistic neuron densities and extrapolated to explore execution times on larger volumes. It was found that touch detection on this data structure scaled much like the optimal algorithm in 3D-space and more specifically that the computing power needed to analyze a meaningful portion of the human cortex is not readily available.},
    author={Brask, Anton and Berendt, Filip},
    year={2020},
    collection={TRITA-EECS-EX}
}

@article{interneuron,
author = {Sah, Nirnath and Sikdar, Sujit K.},
title = {Transition in subicular burst firing neurons from epileptiform activity to suppressed state by feedforward inhibition},
journal = {European Journal of Neuroscience},
volume = {38},
number = {4},
pages = {2542-2556},
keywords = {epileptiform activity, feedforward inhibition, GABAA receptors, rat subiculum},
doi = {https://doi.org/10.1111/ejn.12262},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ejn.12262},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/ejn.12262},
abstract = {Abstract The subiculum, a para-hippocampal structure positioned between the cornu ammonis 1 subfield and the entorhinal cortex, has been implicated in temporal lobe epilepsy in human patients and in animal models of epilepsy. The structure is characterized by the presence of a significant population of burst firing neurons that has been shown previously to lead epileptiform activity locally. Phase transitions in epileptiform activity in neurons following a prolonged challenge with an epileptogenic stimulus has been shown in other brain structures, but not in the subiculum. Considering the importance of the subicular burst firing neurons in the propagation of epileptiform activity to the entorhinal cortex, we have explored the phenomenon of phase transitions in the burst firing neurons of the subiculum in an in vitro rat brain slice model of epileptogenesis. Whole-cell patch-clamp and extracellular field recordings revealed a distinct phenomenon in the subiculum wherein an early hyperexcitable state was followed by a late suppressed state upon continuous perfusion with epileptogenic 4-aminopyridine and magnesium-free medium. The suppressed state was characterized by inhibitory post-synaptic potentials in pyramidal excitatory neurons and bursting activity in local fast-spiking interneurons at a frequency of 0.1–0.8 Hz. The inhibitory post-synaptic potentials were mediated by GABAA receptors that coincided with excitatory synaptic inputs to attenuate action potential discharge. These inhibitory post-synaptic potentials ceased following a cut between the cornu ammonis 1 and subiculum. The suppression of epileptiform activity in the subiculum thus represents a homeostatic response towards the induced hyperexcitability. Our results suggest the importance of feedforward inhibition in exerting this homeostatic control.},
year = {2013}
}
@article{BLUM1973448,
title = {Time bounds for selection},
journal = {Journal of Computer and System Sciences},
volume = {7},
number = {4},
pages = {448-461},
year = {1973},
issn = {0022-0000},
doi = {https://doi.org/10.1016/S0022-0000(73)80033-9},
url = {https://www.sciencedirect.com/science/article/pii/S0022000073800339},
author = {Manuel Blum and Robert W. Floyd and Vaughan Pratt and Ronald L. Rivest and Robert E. Tarjan},
abstract = {The number of comparisons required to select the i-th smallest of n numbers is shown to be at most a linear function of n by analysis of a new selection algorithm—PICK. Specifically, no more than 5.4305 n comparisons are ever required. This bound is improved for extreme values of i, and a new lower bound on the requisite number of comparisons is also proved.}
}
@book{C++11iso,
  added-at = {2012-10-08T01:13:47.000+0200},
  address = {Geneva, Switzerland},
  author = {{ISO}},
  bibdate = {Mon Dec 19 11:12:12 2011},
  bibsource = {http://www.math.utah.edu/pub/tex/bib/isostd.bib},
  biburl = {https://www.bibsonomy.org/bibtex/24b660c16d9a5ab0ad595b1555402c797/gron},
  day = 28,
  interhash = {ff5df6d7fa67f89d7d5ea964dab3e3c9},
  intrahash = {4b660c16d9a5ab0ad595b1555402c797},
  keywords = {C++ Specification Standard},
  month = feb,
  pages = {1338 (est.)},
  publisher = {International Organization for Standardization},
  remark = {Revises ISO/IEC 14882:2003.},
  timestamp = {2012-10-08T01:13:47.000+0200},
  title = {{ISO/IEC 14882:2011 Information technology --- Programming languages --- C++}},
  url = {http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=50372},
  year = 2012
}

@ARTICLE{MacDonald1990-jo,
  title     = "Heuristics for ray tracing using space subdivision",
  author    = "MacDonald, J David and Booth, Kellogg S",
  abstract  = "Ray tracing requires testing of many rays to determine
               intersections with objects. A way of reducing the computation is
               to organize objects into hierarchical data structures. We
               examine two heuristics for space subdivisions using bintrees,
               one based on the intuition that surface area is a good estimate
               of intersection probability, one based on the fact that the
               optimal splitting plane lies between the spatial median and the
               object median planes of a volume. Traversal algorithms using
               cross links between nodes are presented as generalizations of
               ropes in octrees. Simulations of the surface area heuristic and
               the cross link scheme are presented. These results generalize to
               other hierarchical data structures.",
  journal   = "Vis. Comput.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  6,
  number    =  3,
  pages     = "153--166",
  month     =  may,
  year      =  1990,
  language  = "en"
}

@book{knuth97,
  added-at = {2015-06-04T07:16:19.000+0200},
  address = {Boston},
  author = {Knuth, Donald E.},
  biburl = {https://www.bibsonomy.org/bibtex/25dbc415549a1bb86bff7a3842765c31f/ytyoun},
  edition = {Third},
  interhash = {b825ccd550f92a93eefbacd1bec78704},
  intrahash = {5dbc415549a1bb86bff7a3842765c31f},
  isbn = {0201896842 9780201896848},
  keywords = {algorithm knuth no.pdf taocp textbook},
  publisher = {Addison-Wesley},
  refid = {174763889},
  timestamp = {2015-07-29T09:31:05.000+0200},
  title = {The Art of Computer Programming, Volume 2: Seminumerical Algorithms},
  year = 1997
}

@ARTICLE{Trujillo-Estrada2014-uv,
  title     = "Early neuronal loss and axonal/presynaptic damage is associated
               with accelerated amyloid-$\beta$ accumulation in
               {A$\beta$PP/PS1} Alzheimer's disease mice subiculum",
  author    = "Trujillo-Estrada, Laura and D{\'a}vila, Jos{\'e} Carlos and
               S{\'a}nchez-Mejias, Elisabeth and S{\'a}nchez-Varo, Raquel and
               Gomez-Arboledas, Angela and Vizuete, Marisa and Vitorica, Javier
               and Guti{\'e}rrez, Antonia",
  abstract  = "The progressive cognitive decline leading to dementia in
               Alzheimer's disease (AD) patients is the consequence of a severe
               loss of synapses and neurons affecting particular cell
               subpopulations in selected brain areas, with the subiculum being
               one of the earliest regions displaying severe atrophy and
               pathology. The lack of significant neuronal loss in most AD
               models is, in fact, the major shortcoming for the preclinical
               evaluation of drugs that could have greater potential in
               patients to alleviate or prevent this disease. In this study,
               using immunohistochemical and stereological approaches, we have
               analyzed the histopathological events in the subiculum of
               A$\beta$PP751SwedLondon/PS1M146L mice, a transgenic model that
               displays neuronal vulnerability at early ages in hippocampus and
               entorhinal cortex. Our results indicate that the subiculum is
               the earliest affected region in the hippocampus, showing a
               selective early loss of both principal neurons (28\%) and
               SOM-positive interneurons (69\%). In addition, our data
               demonstrate the existence of an early axonal and synaptic
               pathology, which may represent the beginning of the synaptic
               disruption and loss. These neurodegenerative processes occur in
               parallel, and closely related, with the onset and accelerated
               progression of the extracellular amyloid-$\beta$ deposition,
               thus suggesting plaques as major contributors of neuronal/axonal
               damage. Data reported here indicate that this AD model displays
               a selective AD-like neurodegenerative phenotype in highly
               vulnerable regions, including the subiculum, and therefore can
               be a very useful model for testing the therapeutic ability of
               potential compounds to protect neurons and ameliorate disease
               symptoms.",
  journal   = "J. Alzheimers. Dis.",
  publisher = "IOS Press",
  volume    =  42,
  number    =  2,
  pages     = "521--541",
  year      =  2014,
  keywords  = "Alzheimer's disease; amyloid-$\beta$ plaques; axonal damage;
               hippocampus; neuronal loss; subiculum; transgenic mice",
  language  = "en"
}
@ARTICLE{Keller2018-dm,
  title     = "Cell densities in the mouse brain: A systematic review",
  author    = "Keller, Daniel and Er{\"o}, Csaba and Markram, Henry",
  abstract  = "The mouse brain is the most extensively studied brain of all
               species. We performed an exhaustive review of the literature to
               establish our current state of knowledge on cell numbers in
               mouse brain regions, arguably the most fundamental property to
               measure when attempting to understand a brain. The synthesized
               information, collected in one place, can be used by both
               theorists and experimentalists. Although for commonly-studied
               regions cell densities could be obtained for principal cell
               types, overall we know very little about how many cells are
               present in most brain regions and even less about cell-type
               specific densities. There is also substantial variation in cell
               density values obtained from different sources. This suggests
               that we need a new approach to obtain cell density datasets for
               the mouse brain.",
  journal   = "Front. Neuroanat.",
  publisher = "Frontiers Media SA",
  volume    =  12,
  pages     = "83",
  month     =  oct,
  year      =  2018,
  keywords  = "brain regions; cell density; mouse brain; stereology;
               whole-brain atlas",
  language  = "en"
}

@ARTICLE{Mulders1997-bh,
  title     = "Neuron numbers in the presubiculum, parasubiculum, and
               entorhinal area of the rat",
  author    = "Mulders, W H and West, M J and Slomianka, L",
  abstract  = "Estimates of neuron numbers have been useful in studies of
               neurodegenerative disorders, and in their animal models, and in
               the computational modeling of hippocampal function. Although the
               retrohippocampal region (presubiculum, parasubiculum, and
               entorhinal area) is an integral part of the hippocampal
               circuitry and is affected selectively in a number of disorders,
               estimates of neuron numbers in the rat retrohippocampal region
               have yet to be published. Such data are necessary ingredients
               for computational models of the function of this region and will
               also facilitate a comparison of this region in rats and
               primates, which will help to determine how well we may expect
               rat models to predict function and dysfunction in primate
               brains. In the present study, we used the optical fractionator
               to estimate the number of neurons in the rat retrohippocampal
               region. The following estimates were obtained: 3.3 x 10(5) in
               presubicular layers II and III, 1.5 x 10(5) in parasubicular
               layers II and III, 2.2 x 10(5) in the combined pre- and
               parasubicular layers V and VI, 6.6 x 10(4) in medial entorhinal
               area (MEA) layer II, 1.3 x 10(5) in MEA layer III, 1.9 x 10(5)
               in MEA layers V and VI, 4.6 x 10(4) in lateral entorhinal area
               (LEA) layer II, 1.2 x 10(5) in LEA layer III, and 1.4 x 10(5) in
               LEA layers V and VI. A surprising finding was the large numbers
               of neurons in the pre- and parasubiculum, which indicate an
               important role of these areas in the control of the
               entorhino-hippocampal projection. A comparison of the numbers of
               neurons in the hippocampus and entorhinal areas in rats with
               similar estimates in humans revealed that gross input-output
               relations are largely conserved. Differences between rats and
               humans may be accounted for by more prominent
               entorhino-neocortical projections in primates and consequent
               increases in the number of neurons in the hippocampus and
               retrohippocampal region, which are dedicated to these
               projections.",
  journal   = "J. Comp. Neurol.",
  publisher = "Wiley",
  volume    =  385,
  number    =  1,
  pages     = "83--94",
  month     =  aug,
  year      =  1997,
  language  = "en"
}
@ARTICLE{10.3389/fncom.2015.00120,
  
AUTHOR={Reimann, Michael W. and King, James G. and Muller, Eilif B. and Ramaswamy, Srikanth and Markram, Henry},   
	 
TITLE={An algorithm to predict the connectome of neural microcircuits},      
	
JOURNAL={Frontiers in Computational Neuroscience},      
	
VOLUME={9},      
	
YEAR={2015},      
	  
URL={https://www.frontiersin.org/article/10.3389/fncom.2015.00120},       
	
DOI={10.3389/fncom.2015.00120},      
	
ISSN={1662-5188},   
   
ABSTRACT={Experimentally mapping synaptic connections, in terms of the numbers and locations of their synapses and estimating connection probabilities, is still not a tractable task, even for small volumes of tissue. In fact, the six layers of the neocortex contain thousands of unique types of synaptic connections between the many different types of neurons, of which only a handful have been characterized experimentally. Here we present a theoretical framework and a data-driven algorithmic strategy to digitally reconstruct the complete synaptic connectivity between the different types of neurons in a small well-defined volume of tissue—the micro-scale connectome of a neural microcircuit. By enforcing a set of established principles of synaptic connectivity, and leveraging interdependencies between fundamental properties of neural microcircuits to constrain the reconstructed connectivity, the algorithm yields three parameters per connection type that predict the anatomy of all types of biologically viable synaptic connections. The predictions reproduce a spectrum of experimental data on synaptic connectivity not used by the algorithm. We conclude that an algorithmic approach to the connectome can serve as a tool to accelerate experimental mapping, indicating the minimal dataset required to make useful predictions, identifying the datasets required to improve their accuracy, testing the feasibility of experimental measurements, and making it possible to test hypotheses of synaptic connectivity.}
}
@article{
doi:10.1073/pnas.1202128109,
author = {Sean L. Hill  and Yun Wang  and Imad Riachi  and Felix Schürmann  and Henry Markram },
title = {Statistical connectivity provides a sufficient foundation for specific functional connectivity in neocortical neural microcircuits},
journal = {Proceedings of the National Academy of Sciences},
volume = {109},
number = {42},
pages = {E2885-E2894},
year = {2012},
doi = {10.1073/pnas.1202128109},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1202128109},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1202128109},
abstract = {It is well-established that synapse formation involves highly selective chemospecific mechanisms, but how neuron arbors are positioned before synapse formation remains unclear. Using 3D reconstructions of 298 neocortical cells of different types (including nest basket, small basket, large basket, bitufted, pyramidal, and Martinotti cells), we constructed a structural model of a cortical microcircuit, in which cells of different types were independently and randomly placed. We compared the positions of physical appositions resulting from the incidental overlap of axonal and dendritic arbors in the model (statistical structural connectivity) with the positions of putative functional synapses (functional synaptic connectivity) in 90 synaptic connections reconstructed from cortical slice preparations. Overall, we found that statistical connectivity predicted an average of 74 ± 2.7\% (mean ± SEM) synapse location distributions for nine types of cortical connections. This finding suggests that chemospecific attractive and repulsive mechanisms generally do not result in pairwise-specific connectivity. In some cases, however, the predicted distributions do not match precisely, indicating that chemospecific steering and aligning of the arbors may occur for some types of connections. This finding suggests that random alignment of axonal and dendritic arbors provides a sufficient foundation for specific functional connectivity to emerge in local neural microcircuits. In conclusion, neuron arbors in the cortical microcircuitry typically project independently of each other. Our methods provide a means to evaluate exceptions and highlight specific cases of targeted arbor projections for additional study. Furthermore, we observed an important principle for the formation of cortical circuitry; the diversity of neuron morphologies plays an important role in ensuring robust and invariant synaptic patterning between the neurons in the circuit. One implication of this work is that, although specific synapse positions are random, the diverse morphologies of different classes of neocortical pyramidal neurons and interneurons ensure a robust and invariant set of distributed inputs and outputs between specific pre- and postsynaptic populations of neurons (and therefore, a robust and invariant cortical circuit). Synaptic plasticity may act on this foundation to selectively strengthen or weaken multiple recurrent synaptic loops, thereby enabling a diverse range of transient internal states to emerge and a broad range of cortical computations to be performed within the cortical circuit (5). This work describes a method to evaluate the extent to which targeted projection of neuron arbors is necessary to explain synaptic positioning. We found that most synaptic positions can be predicted by the overlap of axons and dendrites, but some exceptions remain. In particular, there must be mechanisms that prevent axons from colliding with the neuron soma. In addition, there seems to be mechanisms that influence the projections of pyramidal neuron axons in relation to the dendrites of other pyramidal neurons. Finally, a special case that remains to be studied (because of the lack of sufficient data) is the case of the Chandelier cell, a type of interneuron that is known to form synapses on the initial segment of pyramidal axons. We then built a computer model of a cortical circuit from hundreds of 3D reconstructed neurons. For some circuits, we generated variant models of the original reconstructions that resulted in thousands of unique neuron morphologies. This model was constructed by randomly positioning six different types of neuron morphologies in five layers in a volume corresponding to a cortical column in the same relative proportions and densities as measured in vitro. The places where the axons and dendrites came into contact were identified, and the innervation pattern was computed as described above. Remarkably, most innervation patterns for the experimental condition matched the computer model very well (Fig. P1). However, some patterns did not. These mismatches suggested that some forms of targeted projections of the neuron fibers are necessary to match the experimental data on specific portions of neurons in specific connection pathways. In addition, we found that the greater the variety of neuron morphologies used to construct the circuit, the more robust the result. To evaluate the extent to which synapse locations are the result of the coordinated development of projections or caused by incidental contacts between axons and dendrites, we measured the distributions of synapses in a standard preparation of young rat somatosensory brain slices. First, pairs of connected neurons were identified by simultaneously stimulating one neuron and recording the voltage in another neuron. Second, sets of connected cells were stained with a dye, the tissue was processed, and careful reconstructions of the full 3D neuron structure were made. Each axon–dendrite connection was carefully examined. If an axonal swelling (bouton) was observed in apposition with a dendrite, then that location was counted as a putative synapse. On average, 80\% of these synapses were verified to be actual functional synapses with EM techniques. By repeating this process for many pairs of neurons, including excitatory pyramidal cells and inhibitory interneurons, we systematically profiled innervation patterns by quantifying the percentage of synapses at different portions of the neuron. Does each type of neuron project its fibers to preferred domains of each of its postsynaptic neurons, or could the specific patterning of synapses between neurons emerge if neurons project their arbors independently of each other? Surprisingly, we found that statistical connectivity (connections with synaptic locations determined solely by the appositions of axons and dendrites) in a model neocortical circuit built from randomly positioned, independently reconstructed 3D neurons accurately predicts most synaptic patterns without any targeting mechanism. We identified three cases that were not well-predicted by such statistical connectivity, indicating the locations where fiber projections are biased to generate more specific targeting. This result shows that the shape of neurons and the random overlap of axons and dendrites provide sufficient foundation for specific functional connectivity to emerge in cortical circuits. The robustness of this result increases with the intrinsic diversity of neuron morphologies in the circuit, showing that one role of neuronal diversity is to build an invariant circuit across different individuals of the same species. The mechanisms determining this selective connectivity have been a subject of active debate for over a century (1), with proposals ranging from Langley’s (2) idea of “chemical relations” between connected neurons to Sperry’s (3) “chemoaffinity hypothesis,” which is the idea that precise synaptic positioning is specified by highly specific chemical signals between neurons. The result is an intriguing map of synaptic connections between all neurons and specific types of neurons, commonly called the connectome. However, the mechanisms of connectome development are still debated (4). A synaptic connection between any two cortical neurons is composed of multiple synapses formed by the axon of the presynaptic neuron and distributed along the axon, soma, and dendrites of the postsynaptic neuron. During development, a broad range of molecular signaling mechanisms act to form the neocortical layers by positioning the neurons, projecting their axonal and dendritic fibers, and forming selective synaptic connections between neurons. Molecular mechanisms also contribute to the activity-triggered formation of synapses between specific pairs of neurons. Thus, synapses are differentially distributed in a selective manner depending on the cell types being connected.}}