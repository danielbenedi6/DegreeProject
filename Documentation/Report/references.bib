@article{MARKRAM201139,
title = {Introducing the Human Brain Project},
journal = {Procedia Computer Science},
volume = {7},
pages = {39-42},
year = {2011},
note = {Proceedings of the 2nd European Future Technologies Conference and Exhibition 2011 (FET 11)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911006806},
author = {Henry Markram and Karlheinz Meier and Thomas Lippert and Sten Grillner and Richard Frackowiak and Stanislas Dehaene and Alois Knoll and Haim Sompolinsky and Kris Verstreken and Javier DeFelipe and Seth Grant and Jean-Pierre Changeux and Alois Saria},
keywords = {Human brain, neuroscience, neuroinformatics, modeling, simulation, supercomputing, HPC, medicine, neuromorphics, neuroprosthetics, neurorobotics},
abstract = {The Human Brain Project (HBP) is a candidate project in the European Union's FET Flagship Program, funded by the ICT Program in the Seventh Framework Program. The project will develop a new integrated strategy for understanding the human brain and a novel research platform that will integrate all the data and knowledge we can acquire about the structure and function of the brain and use it to build unifying models that can be validated by simulations running on supercomputers. The project will drive the development of supercomputing for the life sciences, generate new neuroscientific data as a benchmark for modeling, develop radically new tools for informatics, modeling and simulation, and build virtual laboratories for collaborative basic and clinical studies, drug simulation and virtual prototyping of neuroprosthetic, neuromorphic, and robotic devices.}
}
@article{HERCULANO2012,
author = {Suzana Herculano-Houzel },
title = {The remarkable, yet not extraordinary, human brain as a scaled-up primate brain and its associated cost},
journal = {Proceedings of the National Academy of Sciences},
volume = {109},
number = {supplement\_1},
pages = {10661-10668},
year = {2012},
doi = {10.1073/pnas.1201895109},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1201895109},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1201895109},
abstract = {Neuroscientists have become used to a number of “facts” about the human brain: It has 100 billion neurons and 10- to 50-fold more glial cells; it is the largest-than-expected for its body among primates and mammals in general, and therefore the most cognitively able; it consumes an outstanding 20\% of the total body energy budget despite representing only 2\% of body mass because of an increased metabolic need of its neurons; and it is endowed with an overdeveloped cerebral cortex, the largest compared with brain size. These facts led to the widespread notion that the human brain is literally extraordinary: an outlier among mammalian brains, defying evolutionary rules that apply to other species, with a uniqueness seemingly necessary to justify the superior cognitive abilities of humans over mammals with even larger brains. These facts, with deep implications for neurophysiology and evolutionary biology, are not grounded on solid evidence or sound assumptions, however. Our recent development of a method that allows rapid and reliable quantification of the numbers of cells that compose the whole brain has provided a means to verify these facts. Here, I review this recent evidence and argue that, with 86 billion neurons and just as many nonneuronal cells, the human brain is a scaled-up primate brain in its cellular composition and metabolic cost, with a relatively enlarged cerebral cortex that does not have a relatively larger number of brain neurons yet is remarkable in its cognitive abilities and metabolism simply because of its extremely large number of neurons.}}
 @misc{ wiki:interneurons,
   author = "Physiopedia",
   title = "Interneurons --- Physiopedia{,} ",
   year = "2022",
   url = "https://www.physio-pedia.com/index.php?title=Interneurons&oldid=304286",
   note = "[Online; accessed 10-May-2022]"
 }
 @ARTICLE{Reimann2015-ys,
  title     = "An algorithm to predict the connectome of neural microcircuits",
  author    = "Reimann, Michael W and King, James G and Muller, Eilif B and
               Ramaswamy, Srikanth and Markram, Henry",
  abstract  = "Experimentally mapping synaptic connections, in terms of the
               numbers and locations of their synapses and estimating
               connection probabilities, is still not a tractable task, even
               for small volumes of tissue. In fact, the six layers of the
               neocortex contain thousands of unique types of synaptic
               connections between the many different types of neurons, of
               which only a handful have been characterized experimentally.
               Here we present a theoretical framework and a data-driven
               algorithmic strategy to digitally reconstruct the complete
               synaptic connectivity between the different types of neurons in
               a small well-defined volume of tissue-the micro-scale connectome
               of a neural microcircuit. By enforcing a set of established
               principles of synaptic connectivity, and leveraging
               interdependencies between fundamental properties of neural
               microcircuits to constrain the reconstructed connectivity, the
               algorithm yields three parameters per connection type that
               predict the anatomy of all types of biologically viable synaptic
               connections. The predictions reproduce a spectrum of
               experimental data on synaptic connectivity not used by the
               algorithm. We conclude that an algorithmic approach to the
               connectome can serve as a tool to accelerate experimental
               mapping, indicating the minimal dataset required to make useful
               predictions, identifying the datasets required to improve their
               accuracy, testing the feasibility of experimental measurements,
               and making it possible to test hypotheses of synaptic
               connectivity.",
  journal   = "Front. Comput. Neurosci.",
  publisher = "Frontiers Media SA",
  volume    =  9,
  pages     = "120",
  month     =  oct,
  year      =  2015,
  keywords  = "algorithm development; connectome mapping; cortical circuits; in
               silico; neocortex; somatosensory cortex; synaptic transmission",
  language  = "en"
}
@inproceedings{Furber2006,
title = "High-performance computing for systems of spiking neurons",
abstract = "We propose a bottom-up computer engineering approach to the Grand Challenge of understanding the Architecture of Brain and Mind as a viable complement to top-down modelling and alternative approaches informed by the skills and philosophies of other disciplines. Our approach starts from the observation that brains are built from spiking neurons and then progresses by looking for a systematic way to deploy spiking neurons as components from which useful information processing functions can be constructed, at all stages being informed (but not constrained) by the neural structures and microarchitectures observed by neuroscientists as playing a role in biological systems. In order to explore the behaviours of large-scale complex systems of spiking neuron components we require high-performance computing equipment, and we propose the construction of a machine specifically for this task - a massively parallel computer designed to be a universal spiking neural network simulation engine.",
author = "S.B Furber and Steve Temple and Andrew Brown",
year = "2006",
language = "English",
volume = "2",
pages = "29--36",
booktitle = "Proceedings of AISB'06: Adaptation in Artificial and Biological Systems",
note = "AISB'06: Adaptation in Artificial and Biological Systems ; Conference date: 03-04-2006 Through 06-04-2006",

}
@phdthesis{Adamsson_Vorkapic_2016,
title={A comparison study of Kd-tree, Vp-tree and Octree for storing neuronal morphology data with respect to performance},
url={http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-187026},
abstractNote={In this thesis we investigated performance of Kdtree, Vptree and Octree for storing neuronal morphology data. Two naive list structures were implemented to compare with the space partition data structures. The performance was measured with different sizes of neuronal networks and different types of test cases. A comparison with focus on cache misses, average search time and memory usage was made. Furthermore, measurements gathered quantitative data about each data structure. The results showed significant difference in performance of each data structure. It was concluded that Vptree is more suitable for searches in smaller populations of neurons and for specific nodes in larger populations, while Kdtree is better for volume searches in larger populations. Octree had highest average search time and memory requirement.},
author={Adamsson, Marcus and Vorkapic, Aleksandar}, 
year={2016}
}
@article{10.1145/965105.807481,
author = {Fuchs, Henry and Kedem, Zvi M. and Naylor, Bruce F.},
title = {On Visible Surface Generation by a Priori Tree Structures},
year = {1980},
issue_date = {July 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {0097-8930},
url = {https://doi.org/10.1145/965105.807481},
doi = {10.1145/965105.807481},
abstract = {This paper describes a new algorithm for solving the hidden surface (or line) problem, to more rapidly generate realistic images of 3-D scenes composed of polygons, and presents the development of theoretical foundations in the area as well as additional related algorithms. As in many applications the environment to be displayed consists of polygons many of whose relative geometric relations are static, we attempt to capitalize on this by preprocessing the environment's database so as to decrease the run-time computations required to generate a scene. This preprocessing is based on generating a “binary space partitioning” tree whose in order traversal of visibility priority at run-time will produce a linear order, dependent upon the viewing position, on (parts of) the polygons, which can then be used to easily solve the hidden surface problem. In the application where the entire environment is static with only the viewing-position changing, as is common in simulation, the results presented will be sufficient to solve completely the hidden surface problem.},
journal = {SIGGRAPH Comput. Graph.},
month = {jul},
pages = {124–133},
numpages = {10}
}
@article{Fuchs1980,
author = {Fuchs, Henry and Kedem, Zvi M. and Naylor, Bruce F.},
title = {On Visible Surface Generation by a Priori Tree Structures},
year = {1980},
isbn = {0897910214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800250.807481},
doi = {10.1145/800250.807481},
abstract = {This paper describes a new algorithm for solving the hidden surface (or line) problem, to more rapidly generate realistic images of 3-D scenes composed of polygons, and presents the development of theoretical foundations in the area as well as additional related algorithms. As in many applications the environment to be displayed consists of polygons many of whose relative geometric relations are static, we attempt to capitalize on this by preprocessing the environment's database so as to decrease the run-time computations required to generate a scene. This preprocessing is based on generating a “binary space partitioning” tree whose in order traversal of visibility priority at run-time will produce a linear order, dependent upon the viewing position, on (parts of) the polygons, which can then be used to easily solve the hidden surface problem. In the application where the entire environment is static with only the viewing-position changing, as is common in simulation, the results presented will be sufficient to solve completely the hidden surface problem.},
booktitle = {Proceedings of the 7th Annual Conference on Computer Graphics and Interactive Techniques},
pages = {124–133},
numpages = {10},
location = {Seattle, Washington, USA},
series = {SIGGRAPH '80}
}
@article{Bentley,
author = {Bentley, Jon Louis},
title = {Multidimensional Binary Search Trees Used for Associative Searching},
year = {1975},
issue_date = {Sept. 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/361002.361007},
doi = {10.1145/361002.361007},
abstract = {This paper develops the multidimensional binary search tree (or k-d tree, where k is the dimensionality of the search space) as a data structure for storage of information to be retrieved by associative searches. The k-d tree is defined and examples are given. It is shown to be quite efficient in its storage requirements. A significant advantage of this structure is that a single data structure can handle many types of queries very efficiently. Various utility algorithms are developed; their proven average running times in an n record file are: insertion, O(log n); deletion of the root, O(n(k-1)/k); deletion of a random node, O(log n); and optimization (guarantees logarithmic performance of searches), O(n log n). Search algorithms are given for partial match queries with t keys specified [proven maximum running time of O(n(k-t)/k)] and for nearest neighbor queries [empirically observed average running time of O(log n).] These performances far surpass the best currently known algorithms for these tasks. An algorithm is presented to handle any general intersection query. The main focus of this paper is theoretical. It is felt, however, that k-d trees could be quite useful in many applications, and examples of potential uses are given.},
journal = {Commun. ACM},
month = {sep},
pages = {509–517},
numpages = {9},
keywords = {intersection queries, information retrieval system, attribute, binary search trees, partial match queries, key, nearest neighbor queries, associative retrieval, binary tree insertion}
}

@article{LinjiaSaeidMajid,

  author={Hu, Linjia and Nooshabadi, Saeid and Ahmadi, Majid},

  booktitle={2015 IEEE International Symposium on Circuits and Systems (ISCAS)}, 

  title={Massively parallel KD-tree construction and nearest neighbor search algorithms}, 

  year={2015},

  volume={},

  number={},

  pages={2752-2755},

  abstract={This paper presents parallel algorithms for the construction of k dimensional tree (KD-tree) and nearest neighbor search (NNS) on massively parallel architecture (MPA) of graphics processing unit (GPU). Unlike previous parallel algorithms for KD-tree, for the first time, our parallel algorithms integrate high dimensional KD-tree construction and NNS on an MPA platform. The proposed massively parallel algorithms are of comparable quality as traditional sequential counterparts on CPU, while achieve high speedup performance on both low and high dimensional KD-tree. Low dimensional KD-tree construction and NNS algorithms, presented in this paper, outperform their serial CPU counterparts by a factor of up to 24 and 218, respectively. For high dimensional KD-tree, the speedup factors are even higher, raising to 30 and 242, respectively. Our implementations will potentially benefit real time three-dimensional (3D) image registration and high dimensional descriptor matching.},

  keywords={},

  doi={10.1109/ISCAS.2015.7169256},

  ISSN={2158-1525},

  month={May},
}



@article{WaldHavran06,

  author={Wald, Ingo and Havran, Vlastimil},

  booktitle={2006 IEEE Symposium on Interactive Ray Tracing}, 

  title={On building fast kd-Trees for Ray Tracing, and on doing that in O(N log N)}, 

  year={2006},

  volume={},

  number={},

  pages={61-69},

  abstract={Though a large variety of efficiency structures for ray tracing exist, kd-trees today seem to slowly become the method of choice. In particular, kd-trees built with cost estimation functions such as a surface area heuristic (SAH) seem to be important for reaching high performance. Unfortunately, most algorithms for building such trees have a time complexity of O(N log<sup>2</sup> N), or even O(N<sup>2</sup>). In this paper, we analyze the state of the art in building good kd-trees for ray tracing, and eventually propose an algorithm that builds SAH kd-trees in O(N log N), the theoretical lower bound},

  keywords={},

  doi={10.1109/RT.2006.280216},

  ISSN={},

  month={Sep.},
}

@article{Yucheng,
author = {Lu, Yucheng and Cheng, Luyu and Isenberg, Tobias and Fu, Chi-Wing and Chen, Guoning and Liu, Hui and Deussen, Oliver and Wang, Yunhai},
title = {Curve Complexity Heuristic KD-trees for Neighborhood-based Exploration of 3D Curves},
journal = {Computer Graphics Forum},
volume = {40},
number = {2},
pages = {461-474},
keywords = {CCS Concepts, Human-centered computing → Scientific visualization, Theory of computation → Nearest neighbor algorithms},
doi = {https://doi.org/10.1111/cgf.142647},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.142647},
abstract = {Abstract We introduce the curve complexity heuristic (CCH), a KD-tree construction strategy for 3D curves, which enables interactive exploration of neighborhoods in dense and large line datasets. It can be applied to searches of k-nearest curves (KNC) as well as radius-nearest curves (RNC). The CCH KD-tree construction consists of two steps: (i) 3D curve decomposition that takes into account curve complexity and (ii) KD-tree construction, which involves a novel splitting and early termination strategy. The obtained KD-tree allows us to improve the speed of existing neighborhood search approaches by at least an order of magnitude (i. e., 28×for KNC and 12×for RNC with 98\% accuracy) by considering local curve complexity. We validate this performance with a quantitative evaluation of the quality of search results and computation time. Also, we demonstrate the usefulness of our approach for supporting various applications such as interactive line queries, line opacity optimization, and line abstraction.},
year = {2021}
}

@INPROCEEDINGS{7169256,
  author={Hu, Linjia and Nooshabadi, Saeid and Ahmadi, Majid},
  booktitle={2015 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Massively parallel KD-tree construction and nearest neighbor search algorithms}, 
  year={2015},
  volume={},
  number={},
  pages={2752-2755},
  doi={10.1109/ISCAS.2015.7169256}
}
@article{Sherwood2020,
    author = {Sherwood, Chet C and Miller, Sarah B and Karl, Molly and Stimpson, Cheryl D and Phillips, Kimberley A and Jacobs, Bob and Hof, Patrick R and Raghanti, Mary Ann and Smaers, Jeroen B},
    title = "{Invariant Synapse Density and Neuronal Connectivity Scaling in Primate Neocortical Evolution}",
    journal = {Cerebral Cortex},
    volume = {30},
    number = {10},
    pages = {5604-5615},
    year = {2020},
    month = {06},
    abstract = "{Synapses are involved in the communication of information from one neuron to another. However, a systematic analysis of synapse density in the neocortex from a diversity of species is lacking, limiting what can be understood about the evolution of this fundamental aspect of brain structure. To address this, we quantified synapse density in supragranular layers II–III and infragranular layers V–VI from primary visual cortex and inferior temporal cortex in a sample of 25 species of primates, including humans. We found that synapse densities were relatively constant across these levels of the cortical visual processing hierarchy and did not significantly differ with brain mass, varying by only 1.9-fold across species. We also found that neuron densities decreased in relation to brain enlargement. Consequently, these data show that the number of synapses per neuron significantly rises as a function of brain expansion in these neocortical areas of primates. Humans displayed the highest number of synapses per neuron, but these values were generally within expectations based on brain size. The metabolic and biophysical constraints that regulate uniformity of synapse density, therefore, likely underlie a key principle of neuronal connectivity scaling in primate neocortical evolution.}",
    issn = {1047-3211},
    doi = {10.1093/cercor/bhaa149},
    url = {https://doi.org/10.1093/cercor/bhaa149},
    eprint = {https://academic.oup.com/cercor/article-pdf/30/10/5604/38848884/bhaa149.pdf},
}
@ARTICLE{Neuromorpho1,
  title     = "Mobilizing the base of neuroscience data: the case of neuronal
               morphologies",
  author    = "Ascoli, Giorgio A",
  abstract  = "Despite the explosive growth of bioinformatics, data sharing has
               not yet become routine in neuroscience, possibly because of
               several broad-spanning issues, from data heterogeneity to
               privacy regulations. We present the case of neuronal morphology
               as an ideal example of shareable data. Drawing from recent
               experience, we argue that the tremendous research potential of
               existing (and largely unused) digital reconstructions should
               diffuse any reticence to sharing this type of data.",
  journal   = "Nat. Rev. Neurosci.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  7,
  number    =  4,
  pages     = "318--324",
  month     =  apr,
  year      =  2006,
  language  = "en"
}

@ARTICLE{Neuromorpho2,
  title     = "{NeuroMorpho.Org}: a central resource for neuronal morphologies",
  author    = "Ascoli, Giorgio A and Donohue, Duncan E and Halavi, Maryam",
  journal   = "J. Neurosci.",
  publisher = "Society for Neuroscience",
  volume    =  27,
  number    =  35,
  pages     = "9247--9251",
  month     =  aug,
  year      =  2007,
  language  = "en"
}

@book{carnevale2006neuron,
  title={The NEURON book},
  author={Carnevale, Nicholas T and Hines, Michael L},
  year={2006},
  publisher={Cambridge University Press}
}
@article{8671560,

  author={Akar, Nora Abi and Cumming, Ben and Karakasis, Vasileios and Küsters, Anne and Klijn, Wouter and Peyser, Alexander and Yates, Stuart},

  booktitle={2019 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)}, 

  title={Arbor — A Morphologically-Detailed Neural Network Simulation Library for Contemporary High-Performance Computing Architectures}, 

  year={2019},

  volume={},

  number={},

  pages={274-282},

  abstract={We introduce Arbor, a performance portable library for simulation of large networks of multi-compartment neurons on HPC systems. Arbor is open source software, developed under the auspices of the HBP. The performance portability is by virtue of back-end specific optimizations for x86 multicore, Intel KNL, and NVIDIA GPUs. When coupled with low memory overheads, these optimizations make Arbor an order of magnitude faster than the most widely-used comparable simulation software. The single-node performance can be scaled out to run very large models at extreme scale with efficient weak scaling.},

  keywords={},

  doi={10.1109/EMPDP.2019.8671560},

  ISSN={2377-5750},

  month={Feb},}
@article{Stimberg2019,
    title = {Brian 2, an intuitive and efficient neural simulator},
    volume = {8},
    issn = {2050-084X},
    doi = {10.7554/eLife.47314},
    journal = {eLife},
    author = {Stimberg, Marcel and Brette, Romain and Goodman, Dan FM},
    editor = {Skinner, Frances K},
    month = aug,
    year = {2019},
    pages = {e47314}
}
@ARTICLE{10.3389/fninf.2011.00015,
  
AUTHOR={Kozloski, James and Wagner, John},   
	 
TITLE={An Ultrascalable Solution to Large-scale Neural Tissue Simulation},      
	
JOURNAL={Frontiers in Neuroinformatics},      
	
VOLUME={5},      
	
YEAR={2011},      
	  
URL={https://www.frontiersin.org/article/10.3389/fninf.2011.00015},       
	
DOI={10.3389/fninf.2011.00015},      
	
ISSN={1662-5196},   
   
ABSTRACT={Neural tissue simulation extends requirements and constraints of previous neuronal and neural circuit simulation methods, creating a tissue coordinate system. We have developed a novel tissue volume decomposition, and a hybrid branched cable equation solver. The decomposition divides the simulation into regular tissue blocks and distributes them on a parallel multithreaded machine. The solver computes neurons that have been divided arbitrarily across blocks. We demonstrate thread, strong, and weak scaling of our approach on a machine with more than 4000 nodes and up to four threads per node. Scaling synapses to physiological numbers had little effect on performance, since our decomposition approach generates synapses that are almost always computed locally. The largest simulation included in our scaling results comprised 1 million neurons, 1 billion compartments, and 10 billion conductance-based synapses and gap junctions. We discuss the implications of our ultrascalable Neural Tissue Simulator, and with our results estimate requirements for a simulation at the scale of a human brain.}
}

@article{TPRtree,
author = {Tao, Yufei and Papadias, Dimitris and Sun, Jimeng},
title = {The TPR*-Tree: An Optimized Spatio-Temporal Access Method for Predictive Queries},
year = {2003},
isbn = {0127224424},
publisher = {VLDB Endowment},
abstract = {A predictive spatio-temporal query retrieves the set of moving objects that will intersect a query window during a future time interval. Currently, the only access method for processing such queries in practice is the TPR-tree. In this paper we first perform an analysis to determine the factors that affect the performance of predictive queries and show that several of these factors are not considered by the TPR-tree, which uses the insertion/deletion algorithms of the R*-tree designed for static data. Motivated by this, we propose a new index structure called the TPR*- tree, which takes into account the unique features of dynamic objects through a set of improved construction algorithms. In addition, we provide cost models that determine the optimal performance achievable by any data-partition spatio-temporal access method. Using experimental comparison, we illustrate that the TPR*-tree is nearly-optimal and significantly outperforms the TPR-tree under all conditions.},
booktitle = {Proceedings of the 29th International Conference on Very Large Data Bases - Volume 29},
pages = {790–801},
numpages = {12},
location = {Berlin, Germany},
series = {VLDB '03}
}

@online{wiki:octree,
 author  = "Nü",
 title   = "Schematic drawing of an octree, a data structure of computer science.",
 year    = "2006",
 urlseen = "2022/05/12",
 url     = "https://commons.wikimedia.org/wiki/File:Octree2.png",
 note    = "File: \ttfamily{Octree2.png}",
}

@book{Octree,
author = {Meagher, Donald},
year = {1980},
month = {10},
pages = {},
title = {Octree Encoding: A New Technique for the Representation, Manipulation and Display of Arbitrary 3-D Objects by Computer}
}

@ARTICLE{Quadtree,
  title     = "Quad trees a data structure for retrieval on composite keys",
  author    = "Finkel, R A and Bentley, J L",
  abstract  = "The quad tree is a data structure appropriate for storing information to be retrieved on composite keys. We discuss the specific case of two-dimensional retrieval, although the structure is easily generalised to arbitrary dimensions. Algorithms are given both for staightforward insertion and for a type of balanced insertion into quad trees. Empirical analyses show that the average time for insertion is logarithmic with the tree size. An algorithm for retrieval within regions is presented along with data from empirical studies which imply that searching is reasonably efficient. We define an optimized tree and present an algorithm to accomplish optimization in n log n time. Searching is guaranteed to be fast in optimized trees. Remaining problems include those of deletion from quad trees and merging of quad trees, which seem to be inherently difficult operations.",
  journal   = "Acta Inform.",
  publisher = "Springer Nature",
  volume    =  4,
  number    =  1,
  pages     = "1--9",
  year      =  1974,
  language  = "en"
}

@online{wiki:rtree,
 author  = "Chire",
 title   = "Visulization of a 3D R-tree using ELKI.",
 year    = "2010",
 urlseen = "2022/05/12",
 url     = "https://commons.wikimedia.org/wiki/File:RTree-Visualization-3D.svg",
 note    = "File: \ttfamily{RTree-Visualization-3d.svg}",
}

@article{10.1145/971697.602266,
author = {Guttman, Antonin},
title = {R-Trees: A Dynamic Index Structure for Spatial Searching},
year = {1984},
issue_date = {June 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/971697.602266},
doi = {10.1145/971697.602266},
abstract = {In order to handle spatial data efficiently, as required in computer aided design and geo-data applications, a database system needs an index mechanism that will help it retrieve data items quickly according to their spatial locations However, traditional indexing methods are not well suited to data objects of non-zero size located m multi-dimensional spaces In this paper we describe a dynamic index structure called an R-tree which meets this need, and give algorithms for searching and updating it. We present the results of a series of tests which indicate that the structure performs well, and conclude that it is useful for current database systems in spatial applications},
journal = {SIGMOD Rec.},
month = {jun},
pages = {47–57},
numpages = {11}
}

  
@online{wiki:kdtree,
 author  = "KiwiSunset",
 title   = " A visualization of results obtained by running the Python kd-tree-construction program on [(2,3), (5,4), (9,6), (4,7), (8,1), (7,2)]. ",
 year    = "2006",
 urlseen = "2022/05/12",
 url     = "https://commons.wikimedia.org/wiki/File:Kdtree_2d.svg",
 note    = "File: \ttfamily{Kdtree_2d.svg}",
}

 @phdthesis{Adamsson_Vorkapic_2016, 
    title={A comparison study of Kd-tree, Vp-tree and Octree for storing neuronal morphology data with respect to performance}, 
    url={http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-187026}, 
    abstractNote={In this thesis we investigated performance of Kdtree, Vptree and Octree for storing neuronal morphology data. Two naive list structures were implemented to compare with the space partition data structures. The performance was measured with different sizes of neuronal networks and different types of test cases. A comparison with focus on cache misses, average search time and memory usage was made. Furthermore, measurements gathered quantitative data about each data structure. The results showed significant difference in performance of each data structure. It was concluded that Vptree is more suitable for searches in smaller populations of neurons and for specific nodes in larger populations, while Kdtree is better for volume searches in larger populations. Octree had highest average search time and memory requirement.}, 
    author={Adamsson, Marcus and Vorkapic, Aleksandar}, 
    year={2016}
}

 @phdthesis{Brask_Berendt_2020, 
    series={TRITA-EECS-EX}, 
    title={Analyzing the scalability of R*-tree regarding the neuron touch detection task},
    url={http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-279973},
    abstractNote={A common task within research of neuronal morphology is neuron touch detection, that is finding the points in space where two neurites approach each other to form a synapse. In order to make efficient use of cache memory, it is important to store points that are close in space close in memory. One data structure that aims to tackle this complication is the R*-tree. In this thesis, a spatial query for touch detection was implemented and the scalability of the R*-tree was estimated on realistic neuron densities and extrapolated to explore execution times on larger volumes. It was found that touch detection on this data structure scaled much like the optimal algorithm in 3D-space and more specifically that the computing power needed to analyze a meaningful portion of the human cortex is not readily available.},
    author={Brask, Anton and Berendt, Filip},
    year={2020},
    collection={TRITA-EECS-EX}
}